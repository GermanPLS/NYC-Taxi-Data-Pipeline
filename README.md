# Ingesting NY Taxi Data to Postgres

Este proyecto se basa en el Ejercicio Pr√°ctico  ¬∞1 del **[Data Engineering Zoomcamp](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html#data-engineering-zoomcamp)**
de DataTalks.Club.

Dataset: http://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page

Dictionary: https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

 üöÄ Tecnolog√≠as utilizadas : 

    - Python (para el procesamiento de datos)

    - PostgreSQL (base de datos relacional para almacenar los datos)
 
    - pgAdmin (herramienta web para administrar PostgreSQL)
 
    - Docker & Docker Compose (para la gesti√≥n de contenedores)
 
    - Jupyter Notebook (para desarrollar y probar el c√≥digo de ingesti√≥n y transformaci√≥n de datos)
 
    - Git (para control de versiones)

Clonar el repositorio

    git clone https://github.com/tu_usuario/NYC-Taxi-Data-Pipeline.git
    cd NYC-Taxi-Data-Pipeline



# Paso a Paso 
üìÇ Estructura del proyecto

## 1Ô∏è‚É£ Verificaci√≥n e instalaci√≥n de herramientas

    NYC-Taxi-Data-Pipeline/
    ‚îÇ‚îÄ‚îÄ docker-compose.yml   # Configuraci√≥n de los contenedores
    ‚îÇ‚îÄ‚îÄ requirements.txt     # Dependencias de Python
    ‚îÇ‚îÄ‚îÄ notebooks/           # Jupyter Notebooks para el procesamiento de datos
    ‚îÇ‚îÄ‚îÄ scripts/             # Scripts Python para la extracci√≥n y carga de datos
    ‚îÇ‚îÄ‚îÄ data/                # Archivos de datos descargados
    ‚îÇ‚îÄ‚îÄ README.md            # Documentaci√≥n del proyecto

  Ejecuta los siguientes comandos en la terminal  para verificar si ya estan instaladas, sino hay que installarlas:

   - Verificar si Git est√° instalado
   
         git --version

   - Verificar si Python est√° instalado
     
         python --version
     
   - Verificar si Docker est√° instalado y en ejecuci√≥n
     
         docker --version


## 2Ô∏è‚É£ Configuraci√≥n del entorno del proyecto

  Creamos la estructura del proyecto (Carpetas) en mi disco, para un mejor rendimiento:

    mkdir proyectos
    cd proyectos
    mkdir nyc_taxi_pipeline
    cd nyc_taxi_pipeline
    mkdir notebooks scripts data

Iniciamos Git:

    git init

## 3Ô∏è‚É£ Configurar Docker con PostgreSQL y pgAdmin

   Creamos un archivo docker-compose.yml dentro de nyc_taxi_pipeline para levantar PostgreSQL y pgAdmin:


    version: "3.8"

    services:
      postgres:
        image: postgres:latest
        container_name: postgres_nyc
        restart: always
        environment:
          POSTGRES_USER: admin
          POSTGRES_PASSWORD: admin
          POSTGRES_DB: nyc_taxi
        ports:
          - "5432:5432"
        volumes:
          - postgres_data:/var/lib/postgresql/data
    
      pgadmin:
        image: dpage/pgadmin4
        container_name: pgadmin_nyc
        restart: always
        environment:
          PGADMIN_DEFAULT_EMAIL: admin@admin.com
          PGADMIN_DEFAULT_PASSWORD: admin
        ports:
          - "5050:80"
    
    volumes:
      postgres_data:

Ejecutamos el contenedor:

    docker-compose up -d


Creamos el archivo requirements.txt :

    pandas
    numpy
    sqlalchemy
    psycopg2-binary
    jupyter
    requests
    pyarrow

## 4Ô∏è‚É£ Creaci√≥n del entorno virtual de Python

   Dentro de nyc_taxi_pipeline, creamos el entorno virtual y activamos:


       python3 -m venv venv
       source venv/bin/activate
  
   Instalamos las librer√≠as necesarias:  

      # pip install pandas pyarrow sqlalchemy psycopg2-binary notebook
        pip install -r requirements.txt
        
## 5Ô∏è‚É£ Desarrollo del script en Jupyter Notebook

    jupyter notebook


 Se nos abre una pagina web: http://localhost:8888/ ; debemos invresar en la carpeta `env` :

     New --> Python 3 ( nuevo notebook)

![[imagen1](./imagenes/jupyter_notebook.png)](https://github.com/GermanPLS/NYC-Taxi-Data-Pipeline/blob/79e38102c8cddc7c3641fd0bd9f1b324d3eb64f1/imagenes/jupyter_notebook.png)
     
en el notebook escribimos el c√≥digo para la extracci√≥n, transformaci√≥n y carga en PostgreSQL:

```sh
    import pandas as pd
    from sqlalchemy import create_engine
    
    # Conexi√≥n a PostgreSQL
    engine = create_engine("postgresql://admin:admin@localhost:5432/nyc_taxi")
    
    # Descarga del archivo
    url = "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet"
    df = pd.read_parquet(url)
    
    # Transformaciones necesarias
    df = df.rename(columns=str.lower)  # Ejemplo de transformaci√≥n
    
    # Carga en la base de datos
    df.to_sql("yellow_taxi_data", engine, if_exists="replace", index=False)
    
```


## 6Ô∏è‚É£ Acceso a pgAdmin
    Abre un navegador y accede a `http://localhost:5050` para gestionar la base de datos visualmente.     

    Para la configuracion: 

                              1) Registra un servidor en pgAdmin
                                  Haz clic derecho sobre "Servers" (en el panel izquierdo).
                                  Elige la opci√≥n "Register" ‚Üí "Server...".
                              
                              
                               2) Configura el servidor
                              
                                  Una vez que selecciones "Server", aparecer√° una ventana para configurar la conexi√≥n. Aqu√≠ debes ingresar los siguientes datos:
                              
                                  Pesta√±a "General":
                                      Name: Escribe un nombre para la conexi√≥n.
                                  
                                  
                                  Pesta√±a "Connection":
                              
                                      Host name/address: localhost
                                      Port: 5432 (puerto predeterminado de PostgreSQL).
                                      Maintenance database: nyc_taxi (el nombre de tu base de datos).
                                      Username: admin (o el nombre de usuario configurado).
                                      Password: admin (o la contrase√±a que configuraste).
                                      
                                      Haz clic en Save para guardar la configuraci√≥n.

                                 3) Ver las tablas en pgAdmin:
                                   Ahora deber√≠as ver tu servidor en Servers (en el panel izquierdo). Exp√°ndelo y navega hacia:

                                                 Databases ‚Üí nyc_taxi ‚Üí Schemas ‚Üí public ‚Üí Tables.



                                  4)  Ver los datos de una tabla
                                      Para ver los datos, haz clic derecho sobre la tabla que quieres consultar y selecciona View/Edit Data ‚Üí All Rows.

   ![[imagen2](./imagenes/pgadmin.png)](https://github.com/GermanPLS/NYC-Taxi-Data-Pipeline/blob/399700ee08d89984397dd6568dda4728e6139d55/imagenes/pgadmin.png)                                 
![image](https://github.com/user-attachments/assets/75144a93-5c22-4386-8b72-f953a7ac5a25)

## 7Ô∏è‚É£ Automatizaci√≥n con un script en Python
Creamos un script en la carpeta scripts/:  `extract_transform_load.py`

    import pandas as pd
    import pyarrow
    import fastparquet
    from sqlalchemy import create_engine
    from sqlalchemy.exc import SQLAlchemyError
    
    def main():
        url = "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet"
        db_url = "postgresql://admin:admin@localhost:5432/nyc_taxi"

    try:
        print("Iniciando ejecuci√≥n del script...")
        
        print("Descargando el archivo Parquet...")
        # Cargar los datos desde la URL
        df = pd.read_parquet(url)

        print(f"Archivo descargado y cargado. N√∫mero de filas: {len(df)}")

        if df.empty:
            print("El DataFrame est√° vac√≠o. No se insertar√°n datos.")
            return

        print("Conectando a la base de datos...")
        # Crear conexi√≥n a la base de datos
        engine = create_engine(db_url)
        with engine.connect() as conn:
            print("Insertando datos en la base de datos...")
            df.to_sql("yellow_taxi_data", conn, if_exists="replace", index=False)

        print("Pipeline completado")

    except pd.errors.EmptyDataError:
        print("Error: El archivo Parquet est√° vac√≠o o no es v√°lido.")
    except SQLAlchemyError as e:
        print(f"Error de base de datos: {e}")
    except Exception as e:
        print(f"Error inesperado: {e}")

    if __name__ == "__main__":
    main()


Ejecutamos el script:

    python extract_transform_load.py





    
